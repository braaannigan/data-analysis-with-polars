{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2409664-0829-412c-a8ef-47d15eb04654",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Forecasting electricity demand with Polars\n",
    "In this notebook we learn about:\n",
    "- Loading data\n",
    "- Configuring Polars\n",
    "- Inspecting a `DataFrame`\n",
    "- Selecting rows and columns\n",
    "- Fast-track algorithms on sorted data\n",
    "- Query optimisation\n",
    "- Larger than memory datasets\n",
    "- Visualisation\n",
    "- Building a simple ML forecasting pipeline\n",
    "\n",
    "## About me\n",
    "- PhD in climate physics from University of Oxford\n",
    "- Founded my data science consultantcy at [Rho-Signal](https://www.rhosignal.com/)\n",
    "- Deployed ML pipelines with Polars for [The Electric Storage Company](https://theelectricstoragecompany.com/)\n",
    "- Polars contributor focused on communication and accessibility\n",
    "- Creator of the [Data Analysis with Polars course on Udemy](https://www.udemy.com/course/data-analysis-with-polars/?referralCode=A29DCDA40D369080C05A)\n",
    "- Connect with me on [LinkedIn](https://www.linkedin.com/in/liam-brannigan-9080b214a/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2410acf9-cf18-4503-9d1e-29437b4c522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U polars numpy catboost altair vegafusion[embed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8291b6-2802-4e95-886d-c042a8c02225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,date,timedelta\n",
    "\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "\n",
    "import numpy as np\n",
    "import catboost\n",
    "\n",
    "import altair as alt\n",
    "import vegafusion as vf\n",
    "\n",
    "vf.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b2db26-2285-4df7-9362-784b1c9c9f21",
   "metadata": {},
   "source": [
    "Course materials available from my [Data Analysis with Polars course on Udemy](https://www.udemy.com/course/data-analysis-with-polars/?referralCode=A29DCDA40D369080C05A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2706e1f5-ae3d-4d55-8f77-222d2e9bd946",
   "metadata": {},
   "source": [
    "## Polars at a glance\n",
    "- Dataframe library for tabular data\n",
    "- APIs in Rust, Python, SQL, R, Node\n",
    "- Built-in parallelisation\n",
    "- Scales to larger-than-memory datasets\n",
    "- Apache Arrow in-memory\n",
    "- Type security"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efe9690-0856-4ad5-9c7c-4440a59ab2bc",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "Polars supports a wide range of data sources including:\n",
    "- CSV\n",
    "- Parquet\n",
    "- Arrow/Feather/IPC\n",
    "- JSON\n",
    "- Excel\n",
    "- Databases\n",
    "\n",
    "Recommended: use Parquet to take advantage of columnar selection and dtype preservation\n",
    "\n",
    "> Course material: See the I/O section for lectures on each of these data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664b418-9087-4440-a192-d9522a62422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\"load_features.csv\",try_parse_dates=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67fa80c-b5dc-4f70-bd68-29e7e1f38d03",
   "metadata": {},
   "source": [
    "We can configure how Polars looks and behaves with the `pl.Config` namespace. \n",
    "\n",
    "For example, to set the number of rows that are printed we use `pl.Config.set_tbl_rows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c24e0-53f2-4a5a-a0e0-7ee27ba543a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_tbl_rows(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323dd19f-1c3d-43a1-8e49-90a62f5c08f3",
   "metadata": {},
   "source": [
    "Explore other configuration options in the `pl.Config` namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e967fc0-d2ce-4830-8871-9438f21dcf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca5fb2a-a2a0-42fd-9c34-7dd930a5b5c1",
   "metadata": {},
   "source": [
    "Now when we print the `DataFrame` again we have 6 rows printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ade13-b940-43aa-9db3-6d64777ac9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f103c8-7948-4906-ba8f-c0a4158faac5",
   "metadata": {},
   "source": [
    "## Overview of a DataFrame\n",
    "Polars prints the dtype of each column under the name.\n",
    "\n",
    "We can also get descriptive statistics with `df.describe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5683b26-7702-4e9c-b9f9-b2f4bec510e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0d6daa-e0c8-4e3b-bee1-22186a2f2d6d",
   "metadata": {},
   "source": [
    "Polars stores the `null_count` as an attribute so we can retrieve this cheaply.\n",
    "\n",
    "For wide `DataFrames` we can use `glimpse` to see the first rows printed vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ee65d-4b65-4f81-b860-34200d07dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.glimpse())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9980540-29e5-473c-a9ef-829f198b4fb4",
   "metadata": {},
   "source": [
    "## Selecting and transforming data\n",
    "\n",
    "### Using `[]`\n",
    "\n",
    "We can select rows and columns using `[]` indexing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c485ca-24c7-4eae-8115-3bfefc3bebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:3,[\"time\",\"load\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c06d39-2f2a-42a9-ad2d-728d827346fd",
   "metadata": {},
   "source": [
    "...but using this square bracket approach means that you don't get the benefits of **parallelisation**, **query optimisation** and **streaming** large datasets!\n",
    "\n",
    "Square brackets are best used for:\n",
    "- quickly inspecting data in interactive mode\n",
    "- extracting values at the end of a calculation\n",
    "\n",
    "To really take advantage of Polars we use the **Expression API**.\n",
    "\n",
    "### Selecting and transforming `DataFrames` with the Expression API\n",
    "To filter rows we use the `filter` method. \n",
    "\n",
    "Here we find all rows before a certain date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3f3d1f-a3f5-44c7-8c34-b80628a675fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .filter(\n",
    "        pl.col(\"time\") < datetime(2020,1,1)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76095857-f1ed-4b64-8589-4f45c34ceea7",
   "metadata": {},
   "source": [
    "> For more on filtering rows see the Filtering rows section of the course material. \n",
    "\n",
    "To select a **subset** of columns we use `select`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75171674-0c88-46a2-a825-733d2bdc5576",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .select(\n",
    "        pl.col(\"time\"),pl.col(\"load\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4955dab-24a4-491c-ae6b-3f1922d59a8d",
   "metadata": {},
   "source": [
    "To **add or transform** a column we use `with_columns`.\n",
    "\n",
    "In this example we add feature columns with:\n",
    "- day-of-the-week\n",
    "- one day lagged values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed6d48-bb5f-4d13-b26d-ba9a67d49dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = (\n",
    "    df\n",
    "    .with_columns(\n",
    "        day_of_week = pl.col(\"time\").dt.weekday(),\n",
    "        lag_one_day = pl.col(\"load\").shift(1)\n",
    "    )\n",
    ")\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4ad67c-c16f-4cab-8b92-a6e4ec205567",
   "metadata": {},
   "source": [
    "Polars runs multiple expressions in parallel.\n",
    "\n",
    "> For more on selecting, adding and transforming columns see the Selecting & Transformations section of the course.\n",
    "\n",
    "#### Visualisation\n",
    "We visualise our features using Altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559cdff2-5f36-4568-992a-7b61c107c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    df2.select(\"load\",\"day_of_week\"),\n",
    "    title=\"Box plot of load by day-of-week\",\n",
    "    width=450\n",
    ").mark_boxplot(extent='min-max').encode(\n",
    "    x=\"day_of_week:N\",\n",
    "    y=\"load:Q\",\n",
    "    color=\"day_of_week:N\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceab6f4d-3eaf-406f-9121-4917eb292be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    df2.select(\"lag_one_day\",\"load\",\"day_of_week\"),\n",
    "    title=\"Load vs previous day's load by day-of-week\"\n",
    ").mark_circle().encode(\n",
    "    x=alt.X(\"lag_one_day:Q\",scale=alt.Scale(zero=False)),\n",
    "    y=alt.Y(\"load:Q\",scale=alt.Scale(zero=False)),\n",
    "    color=\"day_of_week:N\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa6d5db-cd91-4d80-a6f4-31a076cbb326",
   "metadata": {},
   "source": [
    "> For more on visualisation with Matplotlib, Seaborn and Plotly see the Visualisation section of the course or [my blog posts on visualisation](https://www.rhosignal.com/tags/visualisation/).\n",
    "\n",
    "### Working with multiple columns\n",
    "We use `pl.col` to reference a column or columns in the Expression API.\n",
    "\n",
    "This could be verbose!\n",
    "\n",
    "Polars has lots of ways to reference multiple columns at once.\n",
    "\n",
    "For example we can do the same expression on all the floating point columns with the dtype in `pl.col`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2907de-196b-42b3-b172-334a99b48eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df2\n",
    "    .with_columns(\n",
    "        pl.col(pl.FLOAT_DTYPES).round()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd48f1b-aa03-4c00-9b2e-eefc66aeb90b",
   "metadata": {},
   "source": [
    "Polars **selectors** also provide ways to do multi-column selections. \n",
    "\n",
    "In this example we use a selector to select the time column and all the temperature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0710200-9759-4dda-8b10-e0eb881b7a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .select(\n",
    "        \"time\",\n",
    "        cs.contains(\"_temp\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdf24bd-d9d2-48dc-a9a4-3352ede6a6c6",
   "metadata": {},
   "source": [
    "> For more on selectors see the Selecting and Transformations section of the course and [the official docs](https://pola-rs.github.io/polars/py-polars/html/reference/selectors.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c72a80-1831-4cc0-b407-11199bed53f7",
   "metadata": {},
   "source": [
    "### Why use expressions?\n",
    "\n",
    "- expressions can be run in **parallel**\n",
    "- expressions can be **optimised** in lazy mode by the query optimiser\n",
    "- `[]` indexing can only be used in eager mode, but expressions can also **be used in lazy mode**\n",
    "\n",
    "Get in the habit of using expressions as your default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0752202a-7934-4589-a675-9004a0b6e8cc",
   "metadata": {},
   "source": [
    "## Fast-track algorithms on sorted data\n",
    "Polars has fast-track algorithms when it knows a column is sorted. These allow optimised operations for:\n",
    "- statistics (min/max/median/quantile)\n",
    "- filter\n",
    "- groupby\n",
    "- join\n",
    "\n",
    "We tell Polars a column is sorted using the `set_sorted` expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bed354-0fb7-4df6-a504-d7df291aa44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df\n",
    "    .with_columns(\n",
    "        pl.col(\"time\").set_sorted()\n",
    "   )\n",
    ")\n",
    "df[\"time\"].flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f71af92-73ee-4118-a5d6-9b8c77852eb9",
   "metadata": {},
   "source": [
    "> For more on fast-track algorithms in the course see the lecture on Sorting in the Selecting & Transformations section, the introductory lecture on groupby in the Statistics & Grouping section and the introductory lecture on joins in the Combining DataFrames section. See also this blog post from my site [introducing sorted algorithms](https://www.rhosignal.com/posts/polars-loves-sorted-data-1-statistics/) and this blog post on [groupby with sorted algorithms](https://www.rhosignal.com/posts/polars-sorted-data-2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c15f5a-d73d-4f1d-8a52-00bae5945b3a",
   "metadata": {},
   "source": [
    "## Lazy mode and query optimisation\n",
    "So far we have used eager mode where code is executed line-by-line.\n",
    "\n",
    "Polars also has a lazy mode where it builds a query plan step-by-step before executing it.\n",
    "\n",
    "In fact expressions in eager mode are really just line-by-line lazy mode under the hood.\n",
    "\n",
    "In this example we start our lazy query from the CSV. We replace `pl.read_csv` with `pl.scan_csv` to show we are starting a lazy query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fb5bd2-0b5c-4f4e-9bc5-c6d1b18f9607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lazy = pl.scan_csv(\"load_features.csv\",try_parse_dates=True)\n",
    "df_lazy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b0cd3a-dda7-494a-8313-9410d25e1e9f",
   "metadata": {},
   "source": [
    "When we run `pl.scan_csv`:\n",
    "- Polars has a look at the first N rows of the CSV to get the column names and infer types\n",
    "- Polars creates a `LazyFrame` where the first step in the query plan is to read the CSV\n",
    "\n",
    "Any additional commands we apply to the `LazyFrame` will update the query plan until we evaluate the query. \n",
    "\n",
    "Here we have a query to create our training `LazyFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df8e785-0e3c-48c2-bf6c-61c05264c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = (\n",
    "    pl.scan_csv(\"load_features.csv\",try_parse_dates=True)\n",
    "    # Add features\n",
    "    .with_columns(\n",
    "        day_of_week = pl.col(\"time\").dt.weekday(),\n",
    "        # lag_one_day = pl.col(\"load\").shift(1)\n",
    "    )\n",
    "    # Filter for records before 2020\n",
    "    .filter(\n",
    "        pl.col(\"time\") < datetime(2020,1,1)\n",
    "    )\n",
    "    # Remove a redundant feature\n",
    "    .select(pl.exclude(\"sunshine\"))\n",
    ")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dc61f1-17ff-4d0f-9214-97dd6f53b4d6",
   "metadata": {},
   "source": [
    "To get the **optimised plan** use `.explain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4fc3a6-5cf2-4bb9-807b-5c117a036bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    df_train.explain()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f724b5-a2d1-4bf4-aca1-a2201caa53fa",
   "metadata": {},
   "source": [
    "`df_train` is a `LazyFrame` rather than a `DataFrame`\n",
    "\n",
    "- `DataFrame` -> expressions operate on the data\n",
    "- `LazyFrame` -> expressions update the query plan\n",
    "\n",
    "When new steps are added Polars will automatically optimise the query plan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ad7134-c384-484f-a4e8-231aec2fbe73",
   "metadata": {},
   "source": [
    "### Types of optimisations\n",
    "- Projection pushdown (identifying relevant columns)\n",
    "- Predicate pushdown (applying filters as early as possible)\n",
    "- Combining predicates (combines multiple filter conditions)\n",
    "- Slice pushdown (limit rows processed as early as possible when limited rows are required)\n",
    "- Common subplan elimination (run duplicated transformations on the same data once and then re-use)\n",
    "- Caching aggregations..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316c683-ddbd-4e90-ae80-9ff40781bca5",
   "metadata": {},
   "source": [
    "We evaluate a lazy query with the `collect` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f41b11d-ae8c-4c2e-9a1a-f29efcacd854",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_train\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32c64cb-1eb6-47ab-b5c8-0b7ce0188e88",
   "metadata": {},
   "source": [
    "> To get started with lazy mode see the Introduction section of the course material. The topic of lazy mode is then returned to within the other sections of the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dc5bdd-be7d-42bd-87dd-397010bb530f",
   "metadata": {},
   "source": [
    "### Streaming large datasets\n",
    "Polars can process a lazy query for larger-than-memory datasets in batches. This is called **streaming** mode.\n",
    "\n",
    "To evaluate a query in streaming mode pass the `streaming=True` argument to collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3f2f2-0647-45c2-99e1-906f164b4371",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_train\n",
    "    .collect(streaming=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f483b-6c80-4e62-9e1d-35f8c8c5d414",
   "metadata": {},
   "source": [
    "> For more on streaming mode see [this high-level video from my youtube channel](https://www.youtube.com/watch?v=3-C0Afs5TXQ) or blogs I have written such as this one on [setting parameters for streaming mode](https://www.rhosignal.com/posts/streaming-chunk-sizes/). Streaming mode is covered in the course primarily in the I/O section on CSV and Parquet files.\n",
    "\n",
    "Not all operations are supported in streaming mode. You can check if a query will run in streaming with `explain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac0a56a-36fe-4407-aeaf-ce7d0f8db28b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    df_train.explain(streaming=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c254f2fb-440a-4442-ad62-0be872d52161",
   "metadata": {},
   "source": [
    "The part of the query plan inside `--- PIPELINE` to `--- END PIPELINE` will be run in streaming mode.\n",
    "\n",
    "See my blog post on [controlling streaming for more info](https://www.rhosignal.com/posts/streaming-chunk-sizes/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651c6562-54e1-4789-91e6-9e047fa50877",
   "metadata": {},
   "source": [
    "Not all operations are supported by streaming - in this case the `shift` expression prevents streaming as it requires data from other batches. Removing it lets the whole pipeline work in streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a45c4b3-cd42-4982-b609-2ca1ba92172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    pl.scan_csv(\"load_features.csv\",try_parse_dates=True)\n",
    "    # Comment out the shift expression\n",
    "    .with_columns(\n",
    "        day_of_week = pl.col(\"time\").dt.weekday(),\n",
    "        # lag_one_day = pl.col(\"load\").shift(1)\n",
    "    )\n",
    "    # Filter for records before 2020\n",
    "    .filter(\n",
    "        pl.col(\"time\") < datetime(2020,1,1)\n",
    "    )\n",
    "    # Remove a redundant feature\n",
    "    .select(pl.exclude(\"sunshine\"))\n",
    "    .explain(streaming=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acdcec8-066a-443c-a40b-6392fdb0ded4",
   "metadata": {},
   "source": [
    "## Machine learning\n",
    "At present you normally convert to `numpy` (or numpy-backed `pandas`) for ML libraries.\n",
    "\n",
    "This situation is changing fast - see [this Sklearn issue thread](https://github.com/scikit-learn/scikit-learn/issues/25896) for some recent developments!\n",
    "\n",
    "Conversion to numpy is typically a relatively cheap operation in the context of an ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b4a92-7182-44ab-9f27-750014d05ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "\n",
    "# Evaluate the LazyFrame if needed\n",
    "if isinstance(df_train,pl.LazyFrame):\n",
    "    df_train = df_train.collect()\n",
    "\n",
    "model = catboost.CatBoostRegressor()\n",
    "X = df_train.drop(\"time\",\"load\").to_pandas()\n",
    "y = df_train[\"load\"].to_pandas()\n",
    "\n",
    "model.fit(X,y,verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059965d8-3368-4cf9-bc7b-5ad05f97c11d",
   "metadata": {},
   "source": [
    "Test the model out-of-sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0f9c4e-236b-4b00-b368-39cfb5c64cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = (\n",
    "    pl.scan_csv(\"load_features.csv\",try_parse_dates=True)\n",
    "    .with_columns(\n",
    "        day_of_week = pl.col(\"time\").dt.weekday(),\n",
    "        lag_one_day = pl.col(\"load\").shift(1)\n",
    "    )\n",
    "    # Filter for records before 2020\n",
    "    .filter(\n",
    "        pl.col(\"time\") >= datetime(2020,1,1)\n",
    "    )\n",
    "    # Remove a redundant feature\n",
    "    .select(pl.exclude(\"sunshine\"))\n",
    "    .collect()\n",
    ")\n",
    "X_test = (\n",
    "    df_test\n",
    "    .drop(\"time\",\"load\")\n",
    "    .to_pandas()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe0582-88c4-4e3a-b926-c6819d400367",
   "metadata": {},
   "source": [
    "Create a `DataFrame` with out-of-sample values and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda703cd-6e8c-436f-9e50-e6d875e1703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = (\n",
    "    df_test\n",
    "    .with_columns(\n",
    "        pl.Series(\"pred\", model.predict(X_test))\n",
    "    )\n",
    ")\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2523168-7216-4583-b556-ba178032aafc",
   "metadata": {},
   "source": [
    "Visualise the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f2bbeb-3c8f-4546-a903-5bc91353c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    alt.Chart(\n",
    "        (\n",
    "            pred_df\n",
    "            .select(\"time\",\"load\",\"pred\")\n",
    "            .melt(id_vars=\"time\")\n",
    "            .with_columns(\n",
    "                pl.col(\"time\").cast(pl.Datetime)\n",
    "            )\n",
    "        ),\n",
    "    title=\"Out-of-sample test\",\n",
    "    width=700\n",
    "    ).mark_line().encode(\n",
    "        x=\"time:T\",\n",
    "        y=\"value:Q\",\n",
    "        color=\"variable:N\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd9d1b3-3207-4d5b-b0da-50393bfbdd0a",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Try Polars on your own data\n",
    "- Check out the course materials\n",
    "- Post questions on StackOverflow if you get stuck\n",
    "- Join [the Polars discord](https://discord.com/invite/4UfP5cfBE7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710dd6ee-517c-40e9-94a1-35b7bb1e09ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.from_pandas(\n",
    "        df\n",
    "        .to_pandas(use_pyarrow_extension_array=True)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d819c-ea02-4789-91bd-a93b365c8be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write_database?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1549b0bb-a9ab-47b8-a42f-4ea9890ad32c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
