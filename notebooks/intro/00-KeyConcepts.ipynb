{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea3afa8a-0219-494a-8f03-12a21d8223de",
   "metadata": {},
   "source": [
    "# Polars: the key concepts\n",
    " \n",
    "This notebook introduces some of the key concepts that make Polars a powerful data analysis tool. \n",
    "\n",
    "The key concepts we meet are:\n",
    "- fast flexible analysis with the Expression API in Polars\n",
    "- easy parallel computations\n",
    "- automatic query optimisation in lazy mode\n",
    "- streaming to work with larger-than-memory datasets in Polars\n",
    "\n",
    "## Importing Polars\n",
    "We begin by importing polars as `pl`. Following this convention will allow you to work with examples from the official documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad810bd3-f454-48b7-9af9-363514fa4176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa74a155-9f01-4d37-9d7a-83f6889ac7f7",
   "metadata": {},
   "source": [
    "We want to restrict how many rows of a `DataFrame` are printed out to the screen. Polars allows us to control configuration using options in `pl.Config`.\n",
    "\n",
    "## Setting configuration options\n",
    "We can adjust default configuration options with `pl.Config`.\n",
    "\n",
    "In this notebook we want Polars to print 6 rows of `DataFrame` so we use `pl.Config.set_tbl_rows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1cf030-ca90-4ccb-b102-6f7d2dac6690",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_tbl_rows(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4c2ff6-4c50-4002-bd07-cb66c6c89e4b",
   "metadata": {},
   "source": [
    "You can see the full range of configuration options here: https://pola-rs.github.io/polars/py-polars/html/reference/config.html\n",
    "\n",
    "In the course we see how to apply the right configuration options in a range of contexts.\n",
    "\n",
    "## Input data\n",
    "Polars can read from a wide range of data formats including CSV, Parquet, Arrow, JSON, Excel and database connections. We cover all of these in the course.\n",
    "\n",
    "For this introduction we use a CSV with the Titanic passenger dataset. This dataset gives details of all the passengers on the Titanic and whether they survived.\n",
    "\n",
    "We begin by setting the path to this CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ea4e6-dbef-4a3e-b2da-0dd7c84a6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = \"../data/titanic.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e0973f-d2ba-4c29-9ecb-2b7b1d58bee8",
   "metadata": {},
   "source": [
    "We read the CSV into a Polars `DataFrame` with the `read_csv` function. \n",
    "\n",
    "We then call `head` to print out the first few rows of the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0407fc1-e41e-4613-9163-56f9daf68d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(csvFile)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd37b789-901d-4259-af96-5a05b732e005",
   "metadata": {},
   "source": [
    "Each row of the `DataFrame` has details about a passenger on the Titanic including the class they travelled in (`Pclass`), their name (`Name`) and `Age`.\n",
    "\n",
    "## Expressions\n",
    "You can use square brackets to select rows and columns in Polars..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1452e27-d791-4852-bd53-220fef08a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:3,[\"Pclass\",\"Name\",\"Age\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecd56c7-e764-4218-bc72-66fe206f54df",
   "metadata": {},
   "source": [
    "...but using this square bracket approach means that you don't get all the benefits of parallelisation and query optimisation.\n",
    "\n",
    "To really make take advantage of Polars we use the Expression API.\n",
    "\n",
    "### Selecting and transforming columns with the Expression API\n",
    "\n",
    "We see a simple example of the Expression API here where we select the `Pclass`, `Name` and `Age` columns inside a `select` statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b12f502-21dc-435d-917d-fcd0ccbef8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .select(\n",
    "        [\n",
    "            pl.col(\"Pclass\"),\n",
    "            pl.col(\"Name\"),\n",
    "            pl.col(\"Age\"),\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd7bd30-04f4-4a16-b01c-89d24374c8de",
   "metadata": {},
   "source": [
    "In the Expression API we use `pl.col` to refer to a column.\n",
    "\n",
    "However, the Expression API allows us not only to refer to a column but also to transform it.\n",
    "\n",
    "In this example we select the same three columns, but this time we get the number of words in each name and we round off the age to the nearest whole number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0430980-ee09-446e-9292-35cf20edd511",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .select(\n",
    "        [\n",
    "            pl.col(\"Pclass\"),\n",
    "            pl.col(\"Name\").str.to_lowercase(),\n",
    "            pl.col(\"Age\").round(2)\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19199543-fb56-40d8-ad59-c9edba58ab96",
   "metadata": {},
   "source": [
    "When we have multiple expressions like this Polars runs them in parallel.\n",
    "\n",
    "We can chain expressions together to do more complicated transformations on a column. \n",
    "\n",
    "In this example we first split the `Name` column into words seperated by a space to get a list of words. In the same step we then count the length of this list. We add this as a new column to the `DataFrame` by giving it an `alias` at the end of the expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98151ca-ea98-47ea-b6af-26c56538591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .select(\n",
    "        [\n",
    "            pl.col(\"Pclass\"),\n",
    "            pl.col(\"Name\"),\n",
    "            pl.col(\"Name\").str.split(\" \").arr.lengths().alias(\"Name_word_count\"),\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498d39e1-3a9b-4c73-8c40-ff3e9ed56097",
   "metadata": {},
   "source": [
    "We look at expressions in detail throughout the course to find the right expression for many different scenarios.\n",
    "\n",
    "### Filtering a `DataFrame` with the Expression API\n",
    "\n",
    "We filter a `DataFrame` by applying a condition to an expression.\n",
    "\n",
    "In this example we find all the passengers over 70 years of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ce72f9-3a9c-4cba-9010-c46894316463",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .filter(\n",
    "        pl.col(\"Age\") > 70\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015f274a-69d7-4215-9ffa-0784bc53dd66",
   "metadata": {},
   "source": [
    "We are not limited to using the Expression API for these operations. The Expression API is at the heart of all data transformations in Polars as we see below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7887c01d-29e1-4871-bb4d-b5499fecd234",
   "metadata": {},
   "source": [
    "## Analytics\n",
    "Polars has a wide range of functionality for analysing data. In the course we look at a wider range of analytic methods and how we can use expressions to write more complicated analysis in a concise way.\n",
    "\n",
    "We begin by getting an overview of the `DataFrame` with `describe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a41d3-be19-446c-829b-bc85f5385312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556f10c-48e8-4355-880f-eedf640b217e",
   "metadata": {},
   "source": [
    "The output of `describe` shows us how many records there are, how many `null` values and some key statistics.\n",
    "\n",
    "### Value counts on a column\n",
    "We use `value_counts` to count occurences of values in a column.\n",
    "\n",
    "In this example we count how many passengers there are in each class with `value_counts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa1e191-8e7c-4c9b-83e5-ea0f7416141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Pclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe37f31-28de-4b82-934e-d698996084a4",
   "metadata": {},
   "source": [
    "### Groupby and aggregations\n",
    "Polars has a fast parallel algorithm for `groupby` operations. \n",
    "\n",
    "Here we first group by the `Survived` and the `Pclass` columns. We then aggregate in `agg` by counting the number of passengers in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72992a3d-5120-4a84-96c2-bed07d079677",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .groupby([\"Survived\",\"Pclass\"])\n",
    "    .agg(\n",
    "        pl.col(\"PassengerId\").count().alias(\"counts\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e5b21f-a7c7-4aa5-b19d-74a24bd47805",
   "metadata": {},
   "source": [
    "We use the Expression API to for each aggregation in `agg`.\n",
    "\n",
    "Groupby operations in Polars are fast because Polars has a parallel algorithm for getting the groupby keys. Aggregations are also fast because Polars runs multiple expressions in `agg` in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6654a50d-ec2e-4d56-9ab4-c58e21784ff6",
   "metadata": {},
   "source": [
    "### Window operations\n",
    "Window operations occur when we want to add a column that reflects not just data from that row but from a related group of rows. Windows occur in many contexts including rolling or temporal statistics and Polars covers these use cases.\n",
    "\n",
    "Another example of a window operation is when we want the percentage breakdown within a group. We use the `over` expression for this.\n",
    "\n",
    "For example, here we use `over` to calculate what percentage of passengers in each class survived "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52484dd-b04d-4dad-8182-f234a0df8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "survivedPercentageDf = (\n",
    "    df\n",
    "    # Groupby Survived and Pclass\n",
    "    .groupby([\"Survived\",\"Pclass\"])\n",
    "    # Count the number of passengers in each group\n",
    "    .agg(\n",
    "        pl.col(\"PassengerId\").count().alias(\"counts\")\n",
    "    )\n",
    "    # Divide the number of passengers in each group by the total passengers in each class\n",
    "    .with_column(\n",
    "        100*(\n",
    "            pl.col(\"counts\")/pl.col(\"counts\").sum().over(\"Pclass\")\n",
    "        )\n",
    "        .alias(\"% Survived\")\n",
    "    )\n",
    "    # Sort the output\n",
    "    .sort([\"Pclass\",\"Survived\"],reverse=True)\n",
    ")\n",
    "survivedPercentageDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b68918e-5b0b-40d8-8cf9-ca5f4077afd8",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "We can use popular plotting libraries like Plotly or Matplotlib with Polars.\n",
    "\n",
    "In this example we create a grouped bar chart of survival by class in Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c73536-dbd9-47a3-8ad4-aa7bfe4e9f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(\n",
    "          x = survivedPercentageDf[\"Pclass\"], \n",
    "          y = survivedPercentageDf[\"% Survived\"],\n",
    "          color = survivedPercentageDf['Survived'], \n",
    "          barmode = 'group',\n",
    "          title=\"% survival by class\",\n",
    "          labels = {\n",
    "              \"x\":\"Passenger class\",\n",
    "              \"y\":\"% Survived\",\n",
    "              \"color\":\"Survived\"\n",
    "          },\n",
    "          height=400\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e18862c-208f-4f65-9bcf-5d75163551e7",
   "metadata": {},
   "source": [
    "## Lazy mode and query optimisation\n",
    "In the examples above we work in eager mode. In eager mode Polars runs each part of a query step-by-step.\n",
    "\n",
    "Polars has a powerful feature called lazy mode. In this mode Polars looks at a query as a whole to make a query graph. Before running the query Polars passes the query graph through its query optimiser to see if there ways to make the query faster.\n",
    "\n",
    "When working with a CSV we can switch from eager mode to eager mode by replacing `read_csv` with `scan_csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82853451-8a88-45b4-9c8b-04ab3d7a9bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.scan_csv(csvFile)\n",
    "    .groupby([\"Survived\",\"Pclass\"])\n",
    "    .agg(\n",
    "        pl.col(\"PassengerId\").count().alias(\"counts\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ff7291-9daf-43ba-860e-d20bd6276625",
   "metadata": {},
   "source": [
    "The output of a lazy query is `LazyFrame` and we see the unoptimized query plan when we output a `LazyFrame`.\n",
    "\n",
    "### Query optimiser\n",
    "We can see the optimised query plan that Polars will actually run by add `describe_optimized_plan` at the end of the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f31781-c8b8-474b-878f-dc16ef666b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    pl.scan_csv(csvFile)\n",
    "    .groupby([\"Survived\",\"Pclass\"])\n",
    "    .agg(\n",
    "        pl.col(\"PassengerId\").count().alias(\"counts\")\n",
    "    )\n",
    "    .describe_optimized_plan()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed924f1-854a-4fcc-bdc4-72fb8b96f6bc",
   "metadata": {},
   "source": [
    "In this example Polars has identified an optimisation:\n",
    "```python\n",
    "PROJECT 3/12 COLUMNS\n",
    "```\n",
    "There are 12 columns in the CSV, but the query optimiser sees that only 3 of these columns are required for the query. When the query is evaluated Polars will `PROJECT` 3 out of 12 columns: Polars will only read the 3 required columns from the CSV. This projection saves memory and computation time.\n",
    "\n",
    "A different optimisation happens when we apply a `filter` to a query. In this case we want the same analysis of survival by class but only for passengers over 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac2d16-8afc-442a-ad7c-e3a776a22b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    pl.scan_csv(csvFile)\n",
    "    .filter(pl.col(\"Age\") > 50)\n",
    "    .groupby([\"Survived\",\"Pclass\"])\n",
    "    .agg(\n",
    "        pl.col(\"PassengerId\").count().alias(\"counts\")\n",
    "    )\n",
    "    .describe_optimized_plan()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdcb136-ce68-41af-8e83-60bdc9db1d57",
   "metadata": {},
   "source": [
    "In this example the query optimiser has seen that:\n",
    "- 4 out of 12 columns are now required `PROJECT 4/12 COLUMNS` and\n",
    "- only passengers over 50 should be selected `SELECTION: Some([(col(\"Age\")) > (50f64)])`\n",
    "\n",
    "These optimisations are applied as Polars reads the CSV file so the whole dataset must not be read into memory.\n",
    "\n",
    "### Query evaluation\n",
    "\n",
    "To evaluate the full query and output a `DataFrame` we call `collect` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1580184-5e2e-4aae-84f8-b22ff42e0fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.scan_csv(csvFile)\n",
    "    .filter(pl.col(\"Age\") > 50)\n",
    "    .groupby([\"Survived\",\"Pclass\"])\n",
    "    .agg(\n",
    "        pl.col(\"PassengerId\").count().alias(\"counts\")\n",
    "    )\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e79edea-55b5-4189-80d9-9083dd4cccae",
   "metadata": {},
   "source": [
    "During development with a large dataset it may be better to limit evaluation to a smaller number of output rows. We can do this by replacing `collect` with `fetch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925ce09e-ee42-4d66-a42b-9e8aec722115",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.scan_csv(csvFile)\n",
    "    .filter(pl.col(\"Age\") > 50)\n",
    "    .groupby([\"Survived\",\"Pclass\"])\n",
    "    .agg(\n",
    "        pl.col(\"PassengerId\").count().alias(\"counts\")\n",
    "    )\n",
    "    .fetch(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef8e7cc-bbd1-4aa2-baec-0e73fd4b1a2e",
   "metadata": {},
   "source": [
    "## Streaming larger-than-memory datasets\n",
    "By default Polars reads your full dataset into memory when evaluating a lazy query. However, if your dataset is too large to fit into memory Polars can run many operations in *streaming* mode. With streaming Polars processes your query in batches rather than all at once.\n",
    "\n",
    "To enable streaming we pass the `allow_streaming = True` argument to `collect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11add235-2654-438c-b795-9dc53e5114d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.scan_csv(csvFile)\n",
    "    .filter(pl.col(\"Age\") > 50)\n",
    "    .groupby([\"Survived\",\"Pclass\"])\n",
    "    .agg(\n",
    "        pl.col(\"PassengerId\").count().alias(\"counts\")\n",
    "    )\n",
    "    .collect(allow_streaming = True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933e3a5-d2c8-45cb-962c-19a9a2f0f5a8",
   "metadata": {},
   "source": [
    "In the course we look at how you can write your own streaming algorithms and we see how streaming affects different queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c5867f-bf81-4e82-b34a-11ba17d3fbeb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This notebook has been a quick overview of the key ideas that make Polars a powerful data analysis tool:\n",
    "- expressions allow us to write complex transformations concisely and run them in parallel\n",
    "- lazy mode allows Polars apply query optimisations that reduce memory usage and computation time\n",
    "- streaming lets us process larger-than-memory datasets with Polars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
